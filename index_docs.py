import sys
sys.stdout.reconfigure(encoding="utf-8")

import os
import json
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
import random

# ================== CONFIG ==================
TIMELINE_PATH = "data/history_timeline.json"
OUT_DIR = "faiss_index"
INDEX_PATH = f"{OUT_DIR}/history.index"
META_PATH = f"{OUT_DIR}/meta.json"

EMBED_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
MIN_LEN = 30
# ============================================


# ðŸ” copy Ä‘Ãºng storyteller
HEROIC_ENDINGS = [
    "Sá»± kiá»‡n nÃ y má»Ÿ ra má»™t chÆ°Æ¡ng sá»­ hÃ o hÃ¹ng cá»§a dÃ¢n tá»™c.",
    "Chiáº¿n cÃ´ng áº¥y kháº³ng Ä‘á»‹nh Ã½ chÃ­ tá»± chá»§ vÃ  sá»©c sá»‘ng bá»n bá»‰ cá»§a ngÆ°á»i Viá»‡t.",
    "ÄÃ¢y lÃ  dáº¥u má»‘c thá»ƒ hiá»‡n báº£n lÄ©nh vÃ  khÃ¡t vá»ng lÃ m chá»§ váº­n má»‡nh dÃ¢n tá»™c.",
]

TRAGIC_ENDINGS = [
    "ÄÃ³ lÃ  giai Ä‘oáº¡n bi thÆ°Æ¡ng, khi Ä‘áº¥t nÆ°á»›c rÆ¡i vÃ o thá»­ thÃ¡ch kháº¯c nghiá»‡t.",
    "Biáº¿n cá»‘ nÃ y Ä‘á»ƒ láº¡i nhá»¯ng máº¥t mÃ¡t sÃ¢u sáº¯c cho váº­n má»‡nh dÃ¢n tá»™c.",
    "Thá»i ká»³ áº¥y ghi dáº¥u ná»—i Ä‘au vÃ  nhá»¯ng tá»•n tháº¥t náº·ng ná» cá»§a Ä‘áº¥t nÆ°á»›c.",
]

def storyteller(year, tone, content):
    content = content.rstrip(".")
    if tone == "heroic":
        return f"NÄƒm {year}, {content}. {random.choice(HEROIC_ENDINGS)}"
    if tone == "tragic":
        return f"NÄƒm {year}, {content}. {random.choice(TRAGIC_ENDINGS)}"
    return f"NÄƒm {year}, {content}."


def pick_tone(tones: list[str]) -> str:
    if "heroic" in tones:
        return "heroic"
    if "tragic" in tones:
        return "tragic"
    return "neutral"


def main():
    os.makedirs(OUT_DIR, exist_ok=True)

    # ðŸ“¥ Load timeline
    with open(TIMELINE_PATH, encoding="utf-8") as f:
        timeline = json.load(f)

    documents = []

    # ðŸ”„ Build stories from canonical events
    for year, block in timeline.items():
        for e in block["events"]:
            tone = pick_tone(e.get("tone", []))
            story = storyteller(int(year), tone, e["event"])

            if len(story) < MIN_LEN:
                continue

            documents.append({
                "year": int(year),
                "event": e["event"],
                "tone": tone,
                "story": story
            })

    print(f"[INFO] Stories collected: {len(documents)}")

    if not documents:
        print("[ERROR] No documents to index.")
        return

    # ðŸ§  Load embedding model
    embedder = SentenceTransformer(EMBED_MODEL)

    texts = [d["story"] for d in documents]

    embeddings = embedder.encode(
        texts,
        convert_to_numpy=True,
        show_progress_bar=True
    ).astype("float32")

    # ðŸ“ Normalize cosine
    faiss.normalize_L2(embeddings)

    # ðŸ—‚ï¸ Build FAISS index
    dim = embeddings.shape[1]
    index = faiss.IndexFlatIP(dim)
    index.add(embeddings)

    faiss.write_index(index, INDEX_PATH)

    # ðŸ§¾ Save rich metadata
    meta = {
        "model": EMBED_MODEL,
        "dimension": dim,
        "count": len(documents),
        "documents": [
            {
                "id": i,
                **documents[i]
            }
            for i in range(len(documents))
        ]
    }

    with open(META_PATH, "w", encoding="utf-8") as f:
        json.dump(meta, f, ensure_ascii=False, indent=2)

    print("[DONE] FAISS index built from timeline successfully")


if __name__ == "__main__":
    main()
