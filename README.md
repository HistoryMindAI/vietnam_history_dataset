# Vietnam History AI â€” Há»‡ thá»‘ng Chatbot Lá»‹ch sá»­ Viá»‡t Nam

Dá»± Ã¡n nÃ y lÃ  há»‡ thá»‘ng Chatbot thÃ´ng minh há»— trá»£ tra cá»©u vÃ  tráº£ lá»i cÃ¡c cÃ¢u há»i vá» lá»‹ch sá»­ Viá»‡t Nam, sá»­ dá»¥ng ká»¹ thuáº­t **RAG (Retrieval-Augmented Generation)** káº¿t há»£p **NLU (Natural Language Understanding)** vÃ  kiáº¿n trÃºc **Data-Driven** (dá»¯ liá»‡u Ä‘á»™ng tá»« `knowledge_base.json`).

## ğŸ¯ Status

```
âœ… Version: 6.0.0
âœ… Tests: 820+ tests passing (26 test files)
âœ… AI Models: 3 ONNX models (Embedding + Cross-Encoder + NLI)
âœ… Architecture: 14-phase pipeline â€” NLU â†’ Intent â†’ Constraint â†’ Conflict â†’ Search â†’ Rerank â†’ NLI â†’ Synthesis â†’ Guardrails
âœ… Data: HuggingFace Dataset (500K+ samples) â†’ FAISS v3 Index (checksum + atomic writes)
âœ… Quality: Enterprise test suite (27 behavioral tests) + Advanced resilience suite (29 tests)
âœ… Status: PRODUCTION READY
```

---

## ğŸš€ Quick Start

### 1. CÃ i Ä‘áº·t

```bash
cd ai-service
pip install -r requirements.txt
```

### 2. Build FAISS Index (tá»« HuggingFace)

```bash
cd ai-service
python scripts/build_from_huggingface.py
# TÃ¹y chá»‰nh: MAX_SAMPLES=100000 python scripts/build_from_huggingface.py
```

### 3. Cháº¡y API

```bash
cd ai-service
uvicorn app.main:app --reload
# â†’ http://localhost:8000
# â†’ Swagger UI: http://localhost:8000/docs
```

### 4. Deploy

#### Docker (Khuyáº¿n nghá»‹)
```bash
docker build -t historymindai:latest ./ai-service
docker run -d -p 8000:8000 historymindai:latest

# Hoáº·c dÃ¹ng Docker Compose
docker-compose up -d
```

#### Deploy tá»± Ä‘á»™ng lÃªn Railway
```bash
# Windows
.\deploy.ps1

# Linux/Mac
chmod +x deploy.sh && ./deploy.sh
```

#### Push lÃªn GitHub
```bash
# Windows
.\push-to-github.ps1

# Linux/Mac
chmod +x push-to-github.sh && ./push-to-github.sh
```

**ğŸ“– Lá»™ trÃ¬nh phÃ¡t triá»ƒn AI**: [AI_DEVELOPMENT_ROADMAP.md](AI_DEVELOPMENT_ROADMAP.md)

---

## ğŸ— Kiáº¿n trÃºc há»‡ thá»‘ng

```mermaid
graph TD
    subgraph "ğŸ–¥ Frontend â€” React"
        A["Giao diá»‡n Chat"]
    end

    subgraph "âš™ï¸ Backend â€” Spring Boot"
        B["API Gateway / Orchestrator"]
    end

    subgraph "ğŸ¤– AI Service â€” FastAPI (v6.0)"
        NLU["NLU Layer<br/>Sá»­a lá»—i, phá»¥c há»“i dáº¥u, entity detection"]
        IC["Intent Classifier<br/>11 intent types, duration guard, fact-check"]
        CE_EXT["Constraint Extractor<br/>Hard constraint consolidation"]
        CD["Conflict Detector<br/>Temporal consistency guard"]
        ENGINE["Query Engine<br/>Multi-strategy search routing"]
        CE["Cross-Encoder Rerank<br/>mmarco multilingual ONNX"]
        NLI["NLI Validator<br/>Entailment checking"]
        AS["Answer Synthesis<br/>Template-based, question-type aware, fact-check"]
        GR["Output Verifier<br/>Truncation, drift, hallucination guard"]
        CTX["Implicit Context<br/>Vietnam scope detection"]
    end

    subgraph "ğŸ’¾ Data Layer"
        D1["FAISS v3 Index â€” Semantic vectors + checksum"]
        D2["meta.json â€” Metadata + Inverted Indexes"]
        D3["knowledge_base.json â€” Aliases, Synonyms, Typos"]
    end

    A -- "HTTP" --> B
    B -- "REST" --> NLU
    NLU --> IC
    IC --> CE_EXT
    CE_EXT --> CD
    CD -->|"conflict? â†’ reject"| ENGINE
    ENGINE --> D1 & D2 & D3
    ENGINE --> CE
    CE --> NLI
    NLI --> AS
    AS --> GR
    GR --> CTX
    CTX --> FORMAT["ğŸ“¤ Response"]
```

---

## ğŸ§  AI Pipeline

```mermaid
flowchart LR
    Q["ğŸ“ CÃ¢u há»i"] --> NLU["ğŸ”¤ NLU<br/>Rewrite + Fix"]
    NLU --> IC["ğŸ¯ Intent<br/>Classifier"]
    IC --> Search["ğŸ” Semantic Search<br/>vietnamese-sbert<br/>130 MB ONNX"]
    Search -->|"Top-50"| Rerank["ğŸ“Š Cross-Encoder<br/>mmarco multilingual<br/>113 MB ONNX"]
    Rerank -->|"Top-10"| NLI["âœ… NLI Validator<br/>MiniLMv2 multilingual<br/>102 MB ONNX"]
    NLI --> Synth["ğŸ“„ Answer<br/>Synthesis"]
    Synth --> Answer["ğŸ’¬ CÃ¢u tráº£ lá»i"]

    style Search fill:#FF9800,color:#fff
    style Rerank fill:#3F51B5,color:#fff
    style NLI fill:#7B1FA2,color:#fff
    style IC fill:#1b4332,color:#fff
```

### 3 AI Models (táº¥t cáº£ cháº¡y local, ONNX, miá»…n phÃ­)

| Model | Chá»©c nÄƒng | KÃ­ch thÆ°á»›c |
|---|---|---|
| `keepitreal/vietnamese-sbert` | Encode cÃ¢u há»i â†’ vector | 130 MB |
| `mmarco-mMiniLMv2-L12-H384-v1` | Re-rank káº¿t quáº£ (14 ngÃ´n ngá»¯) | 113 MB |
| `multilingual-MiniLMv2-L6-mnli-xnli` | Kiá»ƒm tra entailment | 102 MB |
| **Tá»•ng** | | **~345 MB** |

---

## ğŸ”¤ NLU â€” Hiá»ƒu NgÃ´n Ngá»¯ Tá»± NhiÃªn

| TÃ­nh nÄƒng | VÃ­ dá»¥ | Káº¿t quáº£ |
|-----------|-------|---------  |
| **Sá»­a lá»—i chÃ­nh táº£** | `nguyen huye` | â†’ `nguyá»…n huá»‡` |
| **Má»Ÿ rá»™ng viáº¿t táº¯t** | `VN Ä‘á»™c láº­p` | â†’ `Viá»‡t Nam Ä‘á»™c láº­p` |
| **Phá»¥c há»“i dáº¥u** | `tran hung dao` | â†’ `tráº§n hÆ°ng Ä‘áº¡o` |
| **Fuzzy Matching** | `tráº§n hÆ°ng Ä‘ao` | â†’ `tráº§n hÆ°ng Ä‘áº¡o` |
| **Phonetic Normalization** | `cháº§n hÆ°ng Ä‘áº¡o` | â†’ `tráº§n hÆ°ng Ä‘áº¡o` |
| **Synonym Expansion** | `quÃ¢n mÃ´ng cá»•` | â†’ `nguyÃªn mÃ´ng` |
| **Fallback Chain** | KhÃ´ng tÃ¬m Ä‘Æ°á»£c â†’ thá»­ 3 cÃ¡ch | â†’ gá»£i Ã½ alternatives |

---

## ğŸ¯ Intent Classifier â€” PhÃ¢n loáº¡i cÃ¢u há»i

| Intent | MÃ´ táº£ | VÃ­ dá»¥ |
|--------|-------|-------|
| `year_range` | Truy váº¥n khoáº£ng nÄƒm | "Tá»« 1945 Ä‘áº¿n 1975 cÃ³ sá»± kiá»‡n gÃ¬?" |
| `year_specific` | NÄƒm cá»¥ thá»ƒ | "NÄƒm 1945 cÃ³ sá»± kiá»‡n gÃ¬?" |
| `person_query` | NhÃ¢n váº­t lá»‹ch sá»­ | "Tráº§n HÆ°ng Äáº¡o Ä‘Ã¡nh quÃ¢n gÃ¬?" |
| `dynasty_query` | Triá»u Ä‘áº¡i | "NhÃ  Tráº§n tá»“n táº¡i bao lÃ¢u?" |
| `event_query` | Sá»± kiá»‡n / chá»§ Ä‘á» | "Tráº­n Báº¡ch Äáº±ng 938 diá»…n ra tháº¿ nÃ o?" |
| `definition` | Äá»‹nh nghÄ©a | "Tráº§n Quá»‘c Tuáº¥n lÃ  ai?" |
| `relationship` | Má»‘i quan há»‡ | "Tráº§n HÆ°ng Äáº¡o vÃ  Tráº§n Quá»‘c Tuáº¥n lÃ  gÃ¬?" |
| `broad_history` | Lá»‹ch sá»­ tá»•ng quan | "Lá»‹ch sá»­ Viá»‡t Nam qua cÃ¡c triá»u Ä‘áº¡i" |
| `fact_check` | Kiá»ƒm tra sá»± tháº­t | "BÃ¡c Há»“ ra Ä‘i nÄƒm 1991 pháº£i khÃ´ng?" |
| `data_scope` | Pháº¡m vi dá»¯ liá»‡u | "Báº¡n cÃ³ dá»¯ liá»‡u Ä‘áº¿n nÄƒm nÃ o?" |
| `semantic` | Fallback tÃ¬m kiáº¿m ngá»¯ nghÄ©a | Query chung |

> **Duration Guard**: Tá»± Ä‘á»™ng phÃ¡t hiá»‡n "1000 nÄƒm ThÄƒng Long" = ká»· niá»‡m, KHÃ”NG pháº£i nÄƒm 1000. Xá»­ lÃ½ thÃ´ng minh "hÆ¡n 150 nÄƒm chia cáº¯t", "ká»· niá»‡m 1000 nÄƒm".
>
> **Fact-Check**: PhÃ¡t hiá»‡n khi ngÆ°á»i dÃ¹ng nÃªu má»™t sá»± tháº­t sai vÃ  há»i xÃ¡c nháº­n ("...nÄƒm 1991 pháº£i khÃ´ng?") â†’ so sÃ¡nh vá»›i dá»¯ liá»‡u thá»±c â†’ âœ… xÃ¡c nháº­n hoáº·c âŒ sá»­a lá»‹ch sá»±.

---

## ğŸ¤– Query Engine â€” Luá»“ng xá»­ lÃ½

```mermaid
flowchart TD
    INPUT["ğŸ“ CÃ¢u há»i"] --> NLU["ğŸ§  NLU: Rewrite + Fix"]
    NLU --> INTENT["ğŸ¯ Intent Classifier"]
    INTENT --> CREATOR{"TÃ¡c giáº£?"}
    CREATOR -- CÃ³ --> CR["ğŸ¤– Creator Response"]
    CREATOR -- KhÃ´ng --> IDENTITY{"Báº¡n lÃ  ai?"}
    IDENTITY -- CÃ³ --> ID["ğŸ¤– Identity"]
    IDENTITY -- KhÃ´ng --> SCOPE{"Data scope?"}
    SCOPE -- CÃ³ --> DS["ğŸ“Š Data Scope Stats"]
    SCOPE -- KhÃ´ng --> FACTCHECK{"Fact-check?"}
    FACTCHECK -- CÃ³ --> FC["ğŸ” Fact-Check\nâœ… Confirm / âŒ Correct"]
    FACTCHECK -- KhÃ´ng --> YEAR_RANGE{"Khoáº£ng nÄƒm?"}
    YEAR_RANGE -- CÃ³ --> YR["ğŸ“… scan_by_year_range"]
    YEAR_RANGE -- KhÃ´ng --> MULTI_YEAR{"Nhiá»u nÄƒm?"}
    MULTI_YEAR -- CÃ³ --> MY["ğŸ“… scan_by_year Ã— N"]
    MULTI_YEAR -- KhÃ´ng --> ENTITY{"CÃ³ entity?"}
    ENTITY -- CÃ³ --> SAME_CHECK{"Relationship?"}
    SAME_CHECK -- CÃ³ --> SAME["ğŸ”— Same-Entity Detection"]
    SAME_CHECK -- KhÃ´ng --> ME["ğŸ” scan_by_entities"]
    ENTITY -- KhÃ´ng --> DEF{"'lÃ  gÃ¬/lÃ  ai'?"}
    DEF -- CÃ³ --> SEM1["ğŸ§  semantic_search"]
    DEF -- KhÃ´ng --> SINGLE{"NÄƒm Ä‘Æ¡n?"}
    SINGLE -- CÃ³ --> SY["ğŸ“… scan_by_year"]
    SINGLE -- KhÃ´ng --> SEM2["ğŸ§  semantic_search"]

    SAME & ME & YR & MY & SEM1 & SY & SEM2 --> RERANK["ğŸ“Š Cross-Encoder Rerank"]
    RERANK --> NLICHECK["âœ… NLI Validation"]
    NLICHECK --> SYNTH["ğŸ“„ Answer Synthesis"]
    SYNTH --> RESULT{"Káº¿t quáº£?"}
    RESULT -- CÃ³ --> FORMAT["Format Answer"]
    RESULT -- KhÃ´ng --> FALLBACK["ğŸ”„ Fallback Chain"]
    FORMAT --> OUTPUT["ğŸ“¤ JSON Response"]
    FALLBACK --> OUTPUT
    FC --> OUTPUT
    DS --> OUTPUT

    style NLU fill:#1b4332,color:#fff
    style INTENT fill:#1b4332,color:#fff
    style RERANK fill:#3F51B5,color:#fff
    style NLICHECK fill:#7B1FA2,color:#fff
    style SYNTH fill:#FF6F00,color:#fff
```

---

## ğŸ”§ Data-Driven Architecture

> **Muá»‘n thÃªm alias/synonym?** Sá»­a `knowledge_base.json` â€” KHÃ”NG cáº§n sá»­a code.
> **ThÃªm documents?** Rebuild FAISS index â€” inverted indexes tá»± build táº¡i startup.

| Thao tÃ¡c | File cáº§n sá»­a | Code cáº§n sá»­a |
|----------|-------------|-------------|
| ThÃªm alias nhÃ¢n váº­t | `knowledge_base.json` | âŒ KhÃ´ng |
| ThÃªm synonym chá»§ Ä‘á» | `knowledge_base.json` | âŒ KhÃ´ng |
| ThÃªm alias triá»u Ä‘áº¡i | `knowledge_base.json` | âŒ KhÃ´ng |
| ThÃªm viáº¿t táº¯t | `knowledge_base.json` | âŒ KhÃ´ng |
| ThÃªm sá»­a lá»—i chÃ­nh táº£ | `knowledge_base.json` | âŒ KhÃ´ng |
| ThÃªm documents má»›i | Rebuild FAISS | âŒ KhÃ´ng |

### Knowledge Base (`knowledge_base.json` v1.2.0)

| Section | MÃ´ táº£ | VÃ­ dá»¥ |
|---|---|---|
| `person_aliases` | Biá»‡t danh nhÃ¢n váº­t lá»‹ch sá»­ | Tráº§n Quá»‘c Tuáº¥n â†’ Tráº§n HÆ°ng Äáº¡o |
| `topic_synonyms` | Tá»« Ä‘á»“ng nghÄ©a chá»§ Ä‘á» | MÃ´ng Cá»• â†’ NguyÃªn MÃ´ng |
| `dynasty_aliases` | Alias triá»u Ä‘áº¡i | NhÃ  Tráº§n â†’ Tráº§n |
| `abbreviations` | Viáº¿t táº¯t | HCM â†’ Há»“ ChÃ­ Minh |
| `typo_fixes` | Sá»­a lá»—i chÃ­nh táº£ | quangtrung â†’ quang trung |
| `question_patterns` | Máº«u cÃ¢u há»i tÃ¬m kiáº¿m | ai Ä‘Ã£, khi nÃ o, á»Ÿ Ä‘Ã¢u |
| `resistance_synonyms` | Má»Ÿ rá»™ng khÃ¡ng chiáº¿n | khÃ¡ng chiáº¿n â†’ cÃ¡c cuá»™c chiáº¿n cá»¥ thá»ƒ |

> **LÆ°u Ã½**: `HISTORICAL_PHRASES` (cá»¥m tá»« lá»‹ch sá»­ Ä‘a tá»«) vÃ  inverted indexes (PERSON, DYNASTY, KEYWORD) Ä‘Æ°á»£c **tá»± Ä‘á»™ng sinh** táº¡i startup tá»« dá»¯ liá»‡u â€” khÃ´ng cáº§n khai bÃ¡o thá»§ cÃ´ng.

---

## ğŸ§ª Testing

```bash
# Cháº¡y táº¥t cáº£ tests
python -m pytest tests/ -v                              # Full suite (820+ tests)
python -m pytest tests/test_enterprise_levels.py -v      # Enterprise behavioral suite
python -m pytest tests/test_advanced_resilience.py -v     # Advanced resilience suite
python -m pytest tests/test_engine.py -v                 # Engine core tests
```

### Test Suites

| Suite | File | Tests | Focus |
|-------|------|-------|-------|
| **Enterprise Levels** | `test_enterprise_levels.py` | 27 | 6-level behavioral validation (sanity â†’ adversarial) |
| **Advanced Resilience** | `test_advanced_resilience.py` | 29 | Determinism, retrieval integrity, guardrails, chaos, concurrency, performance |
| Engine Core | `test_engine.py` | 130 | Intent, entity, year, fact-check, multi-entity |
| Conflict Detector | `test_conflict_detector.py` | 90+ | Temporal contradiction, constraint extraction |
| Comprehensive | `test_comprehensive.py` | 74 | Integration: accuracy, relevance |
| NLU | `test_nlu.py` | 55 | Rewriting, fuzzy, accents, phonetic |
| Search | `test_search_utils.py` | 53 | Search, indexing, relevance |
| Edge Cases | `test_edge_cases.py` | 35 | Malformed data, boundary |
| Intent Classifier | `test_intent_classifier.py` | 30+ | Intent detection, duration guard |
| Year Extraction | `test_year_extraction.py` | 30 | Year extraction |
| Pipeline | `test_pipeline.py` | 30 | Data pipeline |
| *+ 15 more files* | | 240+ | API, schema, performance, dedup, fuzzy, etc. |
| **Tá»•ng** | **26 files** | **820+** | |

---

## ğŸ“‚ Cáº¥u trÃºc

```
vietnam_history_dataset/
â”œâ”€â”€ ai-service/                            # ğŸ¤– FastAPI AI Service
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py                  # Config paths & constants
â”‚   â”‚   â”‚   â”œâ”€â”€ query_schema.py            # QueryInfo dataclass
â”‚   â”‚   â”‚   â””â”€â”€ startup.py                 # Load models + build indexes
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ engine.py                  # ğŸ§  Query Engine chÃ­nh (~1500 LOC)
â”‚   â”‚   â”‚   â”œâ”€â”€ query_understanding.py     # ğŸ”¤ NLU Layer
â”‚   â”‚   â”‚   â”œâ”€â”€ search_service.py          # ğŸ” Entity resolution + FAISS
â”‚   â”‚   â”‚   â”œâ”€â”€ cross_encoder_service.py   # ğŸ“Š Cross-Encoder Re-ranking
â”‚   â”‚   â”‚   â”œâ”€â”€ nli_validator_service.py   # âœ… NLI Answer Validation
â”‚   â”‚   â”‚   â”œâ”€â”€ intent_classifier.py       # ğŸ¯ Intent Classification (11 types)
â”‚   â”‚   â”‚   â”œâ”€â”€ constraint_extractor.py    # ğŸ“ Constraint Extraction (Phase 11)
â”‚   â”‚   â”‚   â”œâ”€â”€ conflict_detector.py       # âš ï¸ Temporal Conflict Detection
â”‚   â”‚   â”‚   â”œâ”€â”€ answer_synthesis.py        # ğŸ“„ Answer Synthesis + Fact-Check
â”‚   â”‚   â”‚   â”œâ”€â”€ answer_validator.py        # âœ”ï¸ Answer Validation
â”‚   â”‚   â”‚   â”œâ”€â”€ guardrails.py              # ğŸ›¡ï¸ Output Verifier (Phase 5)
â”‚   â”‚   â”‚   â”œâ”€â”€ confidence_scorer.py       # ğŸ“Š Confidence Scoring
â”‚   â”‚   â”‚   â”œâ”€â”€ rewrite_engine.py          # âœï¸ Query Rewriting
â”‚   â”‚   â”‚   â”œâ”€â”€ implicit_context.py        # ğŸŒ Implicit Vietnam Context
â”‚   â”‚   â”‚   â”œâ”€â”€ semantic_intent.py         # ğŸ­ Semantic Intent (war/territorial)
â”‚   â”‚   â”‚   â”œâ”€â”€ semantic_layer.py          # ğŸ”— Semantic Layer
â”‚   â”‚   â”‚   â””â”€â”€ context7_service.py        # Context7 integration
â”‚   â”‚   â””â”€â”€ main.py                        # FastAPI entry point
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ build_from_huggingface.py      # ğŸš€ Pipeline: HuggingFace â†’ FAISS v3
â”‚   â”œâ”€â”€ onnx_model/                        # Embedding model (130 MB)
â”‚   â”œâ”€â”€ onnx_cross_encoder/                # Cross-Encoder model (113 MB)
â”‚   â”œâ”€â”€ onnx_nli/                          # NLI model (102 MB)
â”‚   â”œâ”€â”€ faiss_index/                       # FAISS v3 index + meta.json + checksum
â”‚   â”œâ”€â”€ knowledge_base.json                # ğŸ”‘ Aliases, Synonyms, Typos
â”‚   â””â”€â”€ Dockerfile                         # Docker build config
â”œâ”€â”€ pipeline/                              # Data processing pipeline
â”‚   â”œâ”€â”€ storyteller.py                     # HuggingFace â†’ structured data
â”‚   â”œâ”€â”€ clean_structured_data.py           # Data cleaning
â”‚   â””â”€â”€ index_docs.py                      # FAISS index builder
â”œâ”€â”€ tests/                                 # ğŸ§ª Test suites (26 files, 820+ tests)
â”‚   â”œâ”€â”€ test_enterprise_levels.py          # Enterprise behavioral validation (27 tests)
â”‚   â”œâ”€â”€ test_advanced_resilience.py        # Advanced resilience (29 tests)
â”‚   â””â”€â”€ ...                                # + 24 more test files
â”œâ”€â”€ deploy.ps1 / deploy.sh                 # ğŸš€ Auto deploy scripts
â”œâ”€â”€ push-to-github.ps1 / push-to-github.sh # ğŸ“¤ Auto push scripts
â”œâ”€â”€ docker-compose.yml                     # Docker Compose config
â””â”€â”€ AI_DEVELOPMENT_ROADMAP.md              # ğŸ“– Lá»™ trÃ¬nh phÃ¡t triá»ƒn AI
```

## ğŸ“š Tech Stack

| ThÃ nh pháº§n | CÃ´ng nghá»‡ |
|-----------|-----------|
| Framework | FastAPI + Uvicorn |
| Vector DB | FAISS (Facebook AI) |
| Embedding | `keepitreal/vietnamese-sbert` (ONNX) |
| Reranker | `mmarco-mMiniLMv2-L12-H384-v1` (ONNX) |
| NLI | `multilingual-MiniLMv2-L6-mnli-xnli` (ONNX) |
| NLU | Fuzzy matching, accent restoration, phonetic normalization |
| Intent | Custom rule-based classifier (11 intent types + fact-check) |
| Synthesis | Template-based, question-type aware |
| Data | HuggingFace Datasets, Dynamic Entity Registry |
| Deploy | Docker, Railway, GitHub Actions |

---

_Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn nháº±m gÃ¬n giá»¯ vÃ  truyá»n bÃ¡ kiáº¿n thá»©c lá»‹ch sá»­ Viá»‡t Nam thÃ´ng qua cÃ´ng nghá»‡ AI hiá»‡n Ä‘áº¡i._
