# Vietnam History AI - Há»‡ thá»‘ng Chatbot Lá»‹ch sá»­ Viá»‡t Nam

Dá»± Ã¡n nÃ y lÃ  má»™t há»‡ thá»‘ng Chatbot thÃ´ng minh há»— trá»£ tra cá»©u vÃ  tráº£ lá»i cÃ¡c cÃ¢u há»i vá» lá»‹ch sá»­ Viá»‡t Nam, sá»­ dá»¥ng ká»¹ thuáº­t RAG (Retrieval-Augmented Generation) Ä‘á»ƒ cung cáº¥p thÃ´ng tin chÃ­nh xÃ¡c vÃ  cÃ³ chiá»u sÃ¢u.

## ğŸ— Kiáº¿n trÃºc há»‡ thá»‘ng

Há»‡ thá»‘ng Ä‘Æ°á»£c thiáº¿t káº¿ theo mÃ´ hÃ¬nh 3 lá»›p:

```mermaid
graph TD
    subgraph "ğŸ–¥ Frontend - React"
        A["Giao diá»‡n Chat"]
    end

    subgraph "âš™ï¸ Backend - Spring Boot"
        B["API Gateway / Orchestrator"]
        B1["Quáº£n lÃ½ User"]
        B2["Quáº£n lÃ½ Session"]
    end

    subgraph "ğŸ¤– AI Service - FastAPI"
        NLU["NLU Layer - Query Understanding"]
        C["Query Engine"]
        C1["Semantic Search - FAISS"]
        C2["Entity Resolution (Exact + Fuzzy)"]
        C3["Intent Detection"]
        C4["Fallback Chain"]
    end

    subgraph "ğŸ’¾ Data Layer"
        D1["FAISS Index - 630 vectors"]
        D2["meta.json - Metadata"]
        D3["knowledge_base.json - Aliases"]
        D4["history_timeline.json"]
    end

    A -- "HTTP Request" --> B
    B -- "REST API" --> NLU
    NLU -- "rewrite & expand" --> C
    C --> C1 & C2 & C3
    C1 --> D1
    C2 --> D3
    C3 --> D2
    C1 -- "no results" --> C4
    C4 -- "retry" --> C1
    D4 -. "pipeline build" .-> D1
    D4 -. "pipeline build" .-> D2
```

1. **Frontend (React)**: Giao diá»‡n ngÆ°á»i dÃ¹ng cho phÃ©p tÆ°Æ¡ng tÃ¡c vÃ  trÃ² chuyá»‡n vá»›i Chatbot.
2. **Backend (Spring Boot)**: ÄÃ³ng vai trÃ² lÃ  lá»›p Ä‘iá»u phá»‘i (Orchestrator), xá»­ lÃ½ nghiá»‡p vá»¥ chÃ­nh vÃ  quáº£n lÃ½ ngÆ°á»i dÃ¹ng.
3. **AI Service (FastAPI)**: Cung cáº¥p API xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn, thá»±c hiá»‡n tÃ¬m kiáº¿m ngá»¯ nghÄ©a vÃ  truy xuáº¥t dá»¯ liá»‡u lá»‹ch sá»­.
4. **NLU Layer**: Táº§ng hiá»ƒu ngÃ´n ngá»¯ tá»± nhiÃªn â€” tá»± Ä‘á»™ng sá»­a lá»—i chÃ­nh táº£, má»Ÿ rá»™ng viáº¿t táº¯t, phá»¥c há»“i dáº¥u tiáº¿ng Viá»‡t, fuzzy matching, vÃ  chuáº©n hÃ³a phÃ¡t Ã¢m.

---

## ğŸš€ Pipeline xá»­ lÃ½ dá»¯ liá»‡u (AI Pipeline)

QuÃ¡ trÃ¬nh xÃ¢y dá»±ng cÆ¡ sá»Ÿ tri thá»©c cho AI sá»­ dá»¥ng script táº­p trung `build_from_huggingface.py`:

```mermaid
graph LR
    subgraph "ğŸ“¥ Input"
        A["Vietnam-History-1M-Vi<br/>(HuggingFace Dataset)"]
    end

    subgraph "ğŸ”§ build_from_huggingface.py"
        B1["LÃ m sáº¡ch vÄƒn báº£n"]
        B2["TrÃ­ch xuáº¥t thá»i gian (smart)"]
        B3["Nháº­n diá»‡n thá»±c thá»ƒ<br/>(entity_registry.py)"]
        B4["PhÃ¢n loáº¡i sá»± kiá»‡n & Humanize"]
        B5["Táº¡o Embedding vectors"]
        B6["Build FAISS Index"]
    end

    subgraph "ğŸ“¦ Output"
        D2["faiss_index/index.bin"]
        D3["faiss_index/meta.json"]
    end

    A --> B1 & B2 & B3 & B4
    B1 & B2 & B3 & B4 --> B5
    B5 --> B6
    B6 --> D2 & D3
```

### Script chÃ­nh: `ai-service/scripts/build_from_huggingface.py`

- **Dá»¯ liá»‡u Ä‘áº§u vÃ o**: Táº­p dá»¯ liá»‡u [Vietnam-History-1M-Vi](https://huggingface.co/datasets/minhxthanh/Vietnam-History-1M-Vi) (streaming tá»« HuggingFace).
- **Xá»­ lÃ½**:
  - LÃ m sáº¡ch vÄƒn báº£n, loáº¡i bá» ná»™i dung nhiá»…u/junk.
  - TrÃ­ch xuáº¥t thá»i gian thÃ´ng minh (xá»­ lÃ½ edge case: "ká»‰ niá»‡m 1000 nÄƒm").
  - Nháº­n diá»‡n thá»±c thá»ƒ lá»‹ch sá»­: NhÃ¢n váº­t, Äá»‹a danh, Tá»« khÃ³a (qua `entity_registry.py`).
  - PhÃ¢n loáº¡i tÃ­nh cháº¥t sá»± kiá»‡n (QuÃ¢n sá»±, Thá»ƒ cháº¿, VÄƒn hÃ³a, Kinh táº¿) vÃ  sáº¯c thÃ¡i.
  - Tá»± Ä‘á»™ng humanize text thÃ nh vÄƒn xuÃ´i tiáº¿ng Viá»‡t tá»± nhiÃªn.
  - Táº¡o vector embedding vÃ  build FAISS index.
- **Káº¿t quáº£**: Táº¡o ra `faiss_index/index.bin` vÃ  `faiss_index/meta.json`.

### MÃ´ hÃ¬nh Embedding

- Sá»­ dá»¥ng `keepitreal/vietnamese-sbert` â€” mÃ´ hÃ¬nh tiáº¿ng Viá»‡t chuyÃªn dá»¥ng, há»— trá»£ tá»‘t tÃ¬m kiáº¿m ngá»¯ nghÄ©a.
- Vector Ä‘Æ°á»£c lÆ°u trá»¯ vÃ o **FAISS** (Facebook AI Similarity Search) Ä‘á»ƒ tÃ¬m kiáº¿m tá»‘c Ä‘á»™ cao.

---

## ï¿½ NLU â€” Hiá»ƒu NgÃ´n Ngá»¯ Tá»± NhiÃªn

Há»‡ thá»‘ng trang bá»‹ lá»›p **NLU (Natural Language Understanding)** giÃºp chatbot hiá»ƒu Ä‘Æ°á»£c nhiá»u cÃ¡ch diá»…n Ä‘áº¡t khÃ¡c nhau cho cÃ¹ng má»™t cÃ¢u há»i:

| TÃ­nh nÄƒng | VÃ­ dá»¥ | Káº¿t quáº£ |
|-----------|-------|--------|
| **Sá»­a lá»—i chÃ­nh táº£** | `nguyen huye` | â†’ `nguyá»…n huá»‡` |
| **Má»Ÿ rá»™ng viáº¿t táº¯t** | `VN Ä‘á»™c láº­p` | â†’ `Viá»‡t Nam Ä‘á»™c láº­p` |
| **Phá»¥c há»“i dáº¥u** | `tran hung dao` | â†’ `tráº§n hÆ°ng Ä‘áº¡o` |
| **Fuzzy Matching** (always-on) | `tráº§n hÆ°ng Ä‘ao` (sai dáº¥u) | â†’ tÃ¬m Ä‘Æ°á»£c `tráº§n hÆ°ng Ä‘áº¡o` |
| **Phonetic Normalization** | `cháº§n hÆ°ng Ä‘áº¡o` (lá»—i ch/tr) | â†’ `tráº§n hÆ°ng Ä‘áº¡o` |
| **Multi-query Search** | Ãt káº¿t quáº£ â†’ thá»­ alias/synonym | â†’ tÃ¬m thÃªm documents |
| **Synonym Expansion** | `quÃ¢n mÃ´ng cá»•` | â†’ má»Ÿ rá»™ng sang `nguyÃªn mÃ´ng` |
| **Fallback Chain** | KhÃ´ng tÃ¬m Ä‘Æ°á»£c â†’ thá»­ láº¡i 3 cÃ¡ch | â†’ gá»£i Ã½ cÃ¡ch há»i tá»‘t hÆ¡n |

---

## ï¿½ğŸ¤– AI Service â€” Data-Driven Architecture

Dá»‹ch vá»¥ API sá»­ dá»¥ng kiáº¿n trÃºc **Data-Driven** â€” khÃ´ng hardcode patterns, tá»± Ä‘á»™ng scale theo dá»¯ liá»‡u.

### Tá»•ng quan Query Engine

```mermaid
graph TD
    subgraph "ğŸš€ Startup - Khá»Ÿi táº¡o má»™t láº§n"
        S1["meta.json<br/>(630 documents)"]
        S2["knowledge_base.json<br/>(Aliases & Synonyms)"]
        S1 -- "auto-build" --> IDX["Inverted Indexes"]
        S2 -- "load" --> KB["Knowledge Base"]
    end

    subgraph "ğŸ“‡ Inverted Indexes"
        IDX --> I1["PERSONS_INDEX<br/>tÃªn â†’ doc_ids"]
        IDX --> I2["DYNASTY_INDEX<br/>triá»u Ä‘áº¡i â†’ doc_ids"]
        IDX --> I3["KEYWORD_INDEX<br/>keyword â†’ doc_ids"]
        IDX --> I4["PLACES_INDEX<br/>Ä‘á»‹a danh â†’ doc_ids"]
    end

    subgraph "ğŸ“– Knowledge Base"
        KB --> K1["PERSON_ALIASES<br/>Tráº§n Quá»‘c Tuáº¥n â†’ Tráº§n HÆ°ng Äáº¡o"]
        KB --> K2["TOPIC_SYNONYMS<br/>MÃ´ng Cá»• â†’ NguyÃªn MÃ´ng"]
        KB --> K3["DYNASTY_ALIASES<br/>NhÃ  Tráº§n â†’ Tráº§n"]
    end

    Q["User Query"] --> R["resolve_query_entities()"]
    R -- "tra cá»©u" --> K1 & K2 & K3
    R -- "tra cá»©u" --> I1 & I2 & I3 & I4
    R --> RE["Resolved Entities<br/>{persons, dynasties, topics, places}"]
    RE --> SCAN["scan_by_entities()<br/>O(1) Lookup"]
    SCAN --> RESULT["Matched Documents"]
```

### Chi tiáº¿t: Luá»“ng xá»­ lÃ½ cÃ¢u há»i

```mermaid
flowchart TD
    INPUT["ğŸ“ CÃ¢u há»i ngÆ°á»i dÃ¹ng"] --> NLU["ğŸ§  NLU: Query Rewriting<br/>Fix typo, expand abbr, restore accents"]
    NLU --> CREATOR{"Há»i vá» tÃ¡c giáº£?"}
    CREATOR -- CÃ³ --> CR["ğŸ¤– Creator Response"]
    CREATOR -- KhÃ´ng --> IDENTITY{"Há»i 'báº¡n lÃ  ai'?"}
    IDENTITY -- CÃ³ --> ID["ğŸ¤– Identity Response"]
    IDENTITY -- KhÃ´ng --> YEAR_RANGE{"Khoáº£ng nÄƒm?<br/>VD: tá»« 1225-1400"}
    YEAR_RANGE -- CÃ³ --> YR["ğŸ“… scan_by_year_range()"]
    YEAR_RANGE -- KhÃ´ng --> MULTI_YEAR{"Nhiá»u nÄƒm?<br/>VD: 938 vÃ  1288"}
    MULTI_YEAR -- CÃ³ --> MY["ğŸ“… scan_by_year() x N"]
    MULTI_YEAR -- KhÃ´ng --> ENTITY{"CÃ³ entity?<br/>Exact + Fuzzy Match"}
    ENTITY -- CÃ³ --> ME["ğŸ” scan_by_entities()"]
    ENTITY -- KhÃ´ng --> DEFINITION{"Chá»©a 'lÃ  gÃ¬/lÃ  ai'?"}
    DEFINITION -- CÃ³ --> DEF["ğŸ“– semantic_search()"]
    DEFINITION -- KhÃ´ng --> SINGLE_YEAR{"CÃ³ nÄƒm Ä‘Æ¡n?"}
    SINGLE_YEAR -- CÃ³ --> SY["ğŸ“… scan_by_year()"]
    SINGLE_YEAR -- KhÃ´ng --> SEM["ğŸ§  semantic_search()"]

    YR & MY & ME & DEF & SY & SEM --> RESULT{"CÃ³ káº¿t quáº£?"}
    RESULT -- CÃ³ --> DEDUP["Deduplicate & Enrich"]
    RESULT -- KhÃ´ng --> FALLBACK["ğŸ”„ Fallback Chain<br/>1. Retry rewritten query<br/>2. Try search variations<br/>3. Try original query"]
    FALLBACK --> RESULT2{"CÃ³ káº¿t quáº£?"}
    RESULT2 -- CÃ³ --> DEDUP
    RESULT2 -- KhÃ´ng --> SUGGEST["ğŸ’¡ Smart Suggestion<br/>Gá»£i Ã½ cÃ¡ch há»i tá»‘t hÆ¡n"]
    DEDUP --> FORMAT["Format Answer"]
    FORMAT --> OUTPUT["ğŸ“¤ JSON Response"]
    SUGGEST --> OUTPUT

    style NLU fill:#1b4332,color:#fff
    style FALLBACK fill:#7f5539,color:#fff
    style ME fill:#2d6a4f,color:#fff
    style ENTITY fill:#2d6a4f,color:#fff
```

### Chi tiáº¿t: Entity Resolution (Data-Driven)

Khi user há»i _"Tráº§n Quá»‘c Tuáº¥n vÃ  nhÃ  Tráº§n Ä‘Ã¡nh quÃ¢n MÃ´ng Cá»• á»Ÿ Báº¡ch Äáº±ng"_, há»‡ thá»‘ng xá»­ lÃ½:

```mermaid
graph LR
    Q["Query: Tráº§n Quá»‘c Tuáº¥n vÃ  nhÃ  Tráº§n<br/>Ä‘Ã¡nh quÃ¢n MÃ´ng Cá»• á»Ÿ Báº¡ch Äáº±ng"]

    subgraph "1ï¸âƒ£ Person Aliases"
        Q --> PA["PERSON_ALIASES lookup"]
        PA --> P1["Tráº§n Quá»‘c Tuáº¥n â†’ Tráº§n HÆ°ng Äáº¡o âœ…"]
    end

    subgraph "2ï¸âƒ£ Dynasty Aliases"
        Q --> DA["DYNASTY_ALIASES lookup"]
        DA --> D1["nhÃ  Tráº§n â†’ Tráº§n âœ…"]
    end

    subgraph "3ï¸âƒ£ Topic Synonyms"
        Q --> TS["TOPIC_SYNONYMS lookup"]
        TS --> T1["MÃ´ng Cá»• â†’ NguyÃªn MÃ´ng âœ…"]
    end

    subgraph "4ï¸âƒ£ Places Index"
        Q --> PI["PLACES_INDEX lookup"]
        PI --> PL1["Báº¡ch Äáº±ng âœ…"]
    end

    P1 & D1 & T1 & PL1 --> RESOLVED["Resolved:<br/>persons: Tráº§n HÆ°ng Äáº¡o<br/>dynasties: Tráº§n<br/>topics: NguyÃªn MÃ´ng<br/>places: Báº¡ch Äáº±ng"]

    RESOLVED --> SCAN["scan_by_entities()"]
    SCAN --> |"O(1) per entity"| DOCS["Matched Documents"]
```

### Má»Ÿ rá»™ng há»‡ thá»‘ng

> **Muá»‘n thÃªm nhÃ¢n váº­t/alias má»›i?** Chá»‰ cáº§n sá»­a file `knowledge_base.json` â€” KHÃ”NG cáº§n sá»­a code Python.
>
> **ThÃªm 1000 documents má»›i?** Inverted indexes tá»± build táº¡i startup â€” KHÃ”NG cáº§n cáº¥u hÃ¬nh gÃ¬ thÃªm.
>
> **ThÃªm viáº¿t táº¯t má»›i?** Sá»­a `abbreviations` trong `knowledge_base.json` hoáº·c dict `ABBREVIATIONS` trong `query_understanding.py`.

```mermaid
graph LR
    subgraph "ğŸ”§ Chá»‰ cáº§n sá»­a 1 file"
        KB["knowledge_base.json"]
    end

    subgraph "âœ… Tá»± Ä‘á»™ng scale"
        KB --> |"restart server"| LOAD["_load_knowledge_base()"]
        LOAD --> A1["PERSON_ALIASES má»›i"]
        LOAD --> A2["TOPIC_SYNONYMS má»›i"]
        LOAD --> A3["DYNASTY_ALIASES má»›i"]
        LOAD --> A4["ABBREVIATIONS má»›i"]
    end
```

| Thao tÃ¡c | File cáº§n sá»­a | Code cáº§n sá»­a |
|---|---|---|
| ThÃªm alias nhÃ¢n váº­t | `knowledge_base.json` | âŒ KhÃ´ng |
| ThÃªm synonym chá»§ Ä‘á» | `knowledge_base.json` | âŒ KhÃ´ng |
| ThÃªm alias triá»u Ä‘áº¡i | `knowledge_base.json` | âŒ KhÃ´ng |
| ThÃªm viáº¿t táº¯t | `knowledge_base.json` | âŒ KhÃ´ng |
| ThÃªm tÃªn khÃ´ng dáº¥u | `knowledge_base.json` | âŒ KhÃ´ng (auto-gen tá»« knowledge_base) |
| ThÃªm documents má»›i | `meta.json` (rebuild index) | âŒ KhÃ´ng |

---

## ğŸ§ª Testing

Há»‡ thá»‘ng cÃ³ **411 unit tests** bao phá»§ toÃ n diá»‡n (408 passed, 3 skipped):

```bash
cd ai-service && python -m pytest ../tests/ -v
```

| File | Tests | Ná»™i dung |
|---|---|---|
| `test_engine.py` | 78 | Engine chÃ­nh: intent routing, entity resolution, year queries, multi-entity, edge cases |
| `test_engine_dedup.py` | 13 | Deduplication, text cleaning, keyword extraction |
| `test_nlu.py` | 55 | **NLU**: query rewriting, fuzzy matching, accent restoration, question intent, phonetic normalization, fallback |
| `test_search_utils.py` | 53 | Search utilities: keyword extraction, relevance filtering, inverted indexes |
| `test_comprehensive.py` | 74 | Comprehensive integration tests |
| `test_pipeline.py` | 30 | Data pipeline: storyteller, text cleaning |
| `test_year_extraction.py` | 30 | Year extraction tá»« text |
| `test_text_cleaning.py` | 20 | Text normalization vÃ  cleaning |
| `test_storyteller_unit.py` | 18 | Storyteller unit tests |
| `test_e2e_api.py` | 10 | End-to-end API tests |
| `test_data_quality.py` | 10 | Data quality validation |
| `test_normalize.py` | 5 | Unicode normalization |
| `test_schema_integrity.py` | 5 | Schema validation |
| `test_api.py` | 5 | API endpoint tests |
| `test_performance.py` | 4 | Performance benchmarks |

---

## ğŸ›  HÆ°á»›ng dáº«n cÃ i Ä‘áº·t vÃ  khá»Ÿi cháº¡y

### YÃªu cáº§u há»‡ thá»‘ng

- Python 3.11+
- CÃ¡c thÆ° viá»‡n: `fastapi`, `uvicorn`, `faiss-cpu` (hoáº·c `faiss-gpu`), `sentence-transformers`, `pydantic`.

### ğŸš€ HÆ°á»›ng dáº«n cháº¡y API (Quan trá»ng)

Äá»ƒ khá»Ÿi cháº¡y dá»‹ch vá»¥ API cho chatbot, báº¡n cáº§n thá»±c hiá»‡n cÃ¡c bÆ°á»›c sau:

1. Di chuyá»ƒn vÃ o thÆ° má»¥c `ai-service`:
   ```bash
   cd ai-service
   ```
2. Cháº¡y lá»‡nh khá»Ÿi Ä‘á»™ng server (FastAPI):
   ```bash
   uvicorn app.main:app --reload
   ```
   _(LÆ°u Ã½: Äáº£m báº£o báº¡n Ä‘Ã£ cÃ i Ä‘áº·t Ä‘áº§y Ä‘á»§ cÃ¡c thÆ° viá»‡n Python cáº§n thiáº¿t)_

API sáº½ máº·c Ä‘á»‹nh cháº¡y táº¡i: `http://localhost:8000`

### Cháº¡y Pipeline dá»¯ liá»‡u (Khi cáº§n cáº­p nháº­t dá»¯ liá»‡u)

Script chÃ­nh táº£i dá»¯ liá»‡u tá»« HuggingFace, xá»­ lÃ½, vÃ  build FAISS index trong má»™t láº§n cháº¡y:

```bash
cd ai-service
python scripts/build_from_huggingface.py
```

CÃ³ thá»ƒ tÃ¹y chá»‰nh qua biáº¿n mÃ´i trÆ°á»ng:
```bash
# Sá»‘ samples tá»‘i Ä‘a (máº·c Ä‘á»‹nh: 500,000)
MAX_SAMPLES=100000 python scripts/build_from_huggingface.py
```

---

## ğŸ“‚ Cáº¥u trÃºc thÆ° má»¥c

```
vietnam_history_dataset/
â”œâ”€â”€ ai-service/                       # ğŸ¤– FastAPI AI Service
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py             # Cáº¥u hÃ¬nh paths & constants (incl. NLU)
â”‚   â”‚   â”‚   â””â”€â”€ startup.py            # Build indexes + load knowledge base
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ engine.py             # Query Engine â€” intent routing + fallback
â”‚   â”‚   â”‚   â”œâ”€â”€ query_understanding.py # ğŸ§  NLU Layer (query rewriting, fuzzy match)
â”‚   â”‚   â”‚   â””â”€â”€ search_service.py     # Entity resolution + FAISS search
â”‚   â”‚   â””â”€â”€ main.py                   # FastAPI entry point
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ build_from_huggingface.py  # ğŸš€ Pipeline chÃ­nh: load + process + build FAISS
â”‚   â”‚   â””â”€â”€ entity_registry.py        # Dynamic entity extraction
â”‚   â”œâ”€â”€ faiss_index/
â”‚   â”‚   â”œâ”€â”€ index.bin                 # FAISS vector index
â”‚   â”‚   â””â”€â”€ meta.json                 # Document metadata
â”‚   â””â”€â”€ knowledge_base.json           # ğŸ”‘ Aliases, Synonyms & Abbreviations
â”œâ”€â”€ pipeline/                         # (Legacy) pipeline scripts
â””â”€â”€ tests/
    â”œâ”€â”€ test_engine.py                # Engine core tests (78)
    â”œâ”€â”€ test_engine_dedup.py          # Dedup & text cleaning (13)
    â”œâ”€â”€ test_nlu.py                   # ğŸ§  NLU tests (55)
    â”œâ”€â”€ test_search_utils.py          # Search & indexing (53)
    â””â”€â”€ ... (15 test files total)     # 411 tests total
```

## ğŸ“š CÃ´ng nghá»‡ sá»­ dá»¥ng

- **NgÃ´n ngá»¯**: Python
- **Framework**: FastAPI
- **Vector Database**: FAISS
- **AI Model**: `keepitreal/vietnamese-sbert` (ONNX) cho embedding tiáº¿ng Viá»‡t
- **Data Processing**: HuggingFace Datasets, Dynamic Entity Registry, Regex.
- **NLU**: Query rewriting, Fuzzy matching, Accent restoration, Phonetic normalization, Multi-query search (Python stdlib)

---

_Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn nháº±m gÃ¬n giá»¯ vÃ  truyá»n bÃ¡ kiáº¿n thá»©c lá»‹ch sá»­ Viá»‡t Nam thÃ´ng qua cÃ´ng nghá»‡ AI hiá»‡n Ä‘áº¡i._
