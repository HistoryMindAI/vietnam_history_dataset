# ğŸ§  Lá»™ TrÃ¬nh PhÃ¡t Triá»ƒn AI Engine â€” HistoryMindAI

> TÃ i liá»‡u nÃ y giáº£i thÃ­ch **táº¡i sao** há»‡ thá»‘ng AI Ä‘Æ°á»£c thiáº¿t káº¿ nhÆ° hiá»‡n táº¡i â€” má»—i quyáº¿t Ä‘á»‹nh, má»—i láº§n thay Ä‘á»•i hÆ°á»›ng Ä‘i, vÃ  lÃ½ do Ä‘áº±ng sau viá»‡c chá»n tá»«ng model.

---

## Má»¥c tiÃªu

- **Hiá»ƒu cÃ¢u há»i tiáº¿ng Viá»‡t** (cÃ³ dáº¥u, khÃ´ng dáº¥u, viáº¿t táº¯t, lá»—i chÃ­nh táº£)
- **Tráº£ lá»i chÃ­nh xÃ¡c**, khÃ´ng lá»‡ch chá»§ Ä‘á»
- **Miá»…n phÃ­ 100%**, khÃ´ng phá»¥ thuá»™c API tráº£ phÃ­
- **Deploy Ä‘Æ°á»£c** trÃªn GitHub / Railway (~512MB RAM)

---

## Timeline tá»•ng quan

```mermaid
timeline
    title Lá»™ trÃ¬nh phÃ¡t triá»ƒn AI Engine
    Giai Ä‘oáº¡n 1 : Semantic Search cÆ¡ báº£n
                 : paraphrase-multilingual-MiniLM
                 : Káº¿t quáº£ TV kÃ©m
    Giai Ä‘oáº¡n 2 : Chuyá»ƒn sang Vietnamese-SBERT
                 : ONNX Runtime thay PyTorch
                 : TÃ¬m kiáº¿m TV cáº£i thiá»‡n
    Giai Ä‘oáº¡n 3 : ThÃªm Cross-Encoder Re-ranking
                 : ms-marco MiniLM (chá»‰ English)
                 : Re-rank TV sai hoÃ n toÃ n
    Giai Ä‘oáº¡n 4 : NghiÃªn cá»©u giáº£i phÃ¡p nÃ¢ng cao
                 : Loáº¡i GPT-4 vÃ¬ tá»‘n phÃ­
                 : Loáº¡i LLM 7B vÃ¬ quÃ¡ náº·ng
    Giai Ä‘oáº¡n 5 : Cross-Encoder Multilingual
                 : mmarco-mMiniLMv2 (14 ngÃ´n ngá»¯)
                 : ChÃªnh lá»‡ch score ~13 Ä‘iá»ƒm
    Giai Ä‘oáº¡n 6 : NLI Answer Validator
                 : MiniLMv2-L6 multilingual NLI
                 : Entailment filtering
    Giai Ä‘oáº¡n 7 : Intent Classifier + Answer Synthesis
                 : 10 intent types, duration guard
                 : Template-based answer formatting
    Giai Ä‘oáº¡n 8 : Data-Driven Architecture
                 : knowledge_base.json
                 : Dynamic entity registry
                 : Inverted indexes at startup
    Giai Ä‘oáº¡n 9 : Robustness + Bug Fixing
                 : 629+ tests, 24 test files
                 : Null safety, type coercion
                 : Edge case handling
```

---

## Giai Ä‘oáº¡n 1: Semantic Search cÆ¡ báº£n

DÃ¹ng **Sentence Transformer** Ä‘á»ƒ encode cÃ¢u há»i thÃ nh vector, tÃ¬m kiáº¿m trong FAISS index.

**Model:** `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`

**Váº¥n Ä‘á»:** Model multilingual chung chung, **khÃ´ng tá»‘i Æ°u cho tiáº¿ng Viá»‡t**. Vá»›i cÃ¢u há»i khÃ´ng dáº¥u (vÃ­ dá»¥: `"tran hung dao"`), káº¿t quáº£ ráº¥t kÃ©m. KhÃ´ng cÃ³ cÆ¡ cháº¿ re-ranking â†’ káº¿t quáº£ thÃ´ tá»« FAISS thÆ°á»ng láº«n nhiá»u noise.

> **BÃ i há»c:** Multilingual â‰  tá»‘t cho má»i ngÃ´n ngá»¯. Cáº§n model Ä‘Æ°á»£c **train riÃªng** cho tiáº¿ng Viá»‡t.

---

## Giai Ä‘oáº¡n 2: Vietnamese-SBERT + ONNX

Thay embedding model báº±ng **`keepitreal/vietnamese-sbert`** â€” model Sentence-BERT Ä‘Æ°á»£c train riÃªng trÃªn dá»¯ liá»‡u tiáº¿ng Viá»‡t.

### Táº¡i sao chá»n model nÃ y?

```mermaid
graph LR
    subgraph "âŒ paraphrase-multilingual"
        A1["50+ ngÃ´n ngá»¯<br/>Chung chung"]
        A2["~180 MB ONNX"]
        A3["TV: Trung bÃ¬nh"]
    end
    subgraph "âœ… vietnamese-sbert"
        B1["Tiáº¿ng Viá»‡t chuyÃªn biá»‡t"]
        B2["~130 MB ONNX"]
        B3["TV: Tá»‘t"]
    end
    A1 -.->|Thay tháº¿| B1
```

### Táº¡i sao dÃ¹ng ONNX thay PyTorch?

```mermaid
graph TD
    subgraph "âŒ PyTorch Runtime"
        P1["torch ~2 GB"]
        P2["Inference cháº­m hÆ¡n"]
        P3["RAM cao"]
    end
    subgraph "âœ… ONNX Runtime"
        O1["onnxruntime ~50 MB"]
        O2["Inference nhanh 2-3x trÃªn CPU"]
        O3["RAM tháº¥p, phÃ¹ há»£p Railway"]
    end
    P1 -.->|"Tiáº¿t kiá»‡m ~1.95 GB"| O1
```

**Káº¿t quáº£:** TÃ¬m kiáº¿m tiáº¿ng Viá»‡t cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ. NhÆ°ng **thá»© tá»± káº¿t quáº£ khÃ´ng tá»‘i Æ°u** â†’ cáº§n re-ranking.

---

## Giai Ä‘oáº¡n 3: ThÃªm Cross-Encoder Re-ranking

### Váº¥n Ä‘á»

FAISS tráº£ vá» top-K dá»±a trÃªn cosine similarity, nhÆ°ng káº¿t quáº£ #5 cÃ³ thá»ƒ phÃ¹ há»£p hÆ¡n káº¿t quáº£ #1. Bi-encoder nhanh nhÆ°ng **khÃ´ng chÃ­nh xÃ¡c báº±ng cross-encoder**.

### CÃ¡ch hoáº¡t Ä‘á»™ng

```mermaid
flowchart LR
    Q["CÃ¢u há»i"] --> BiEnc["Bi-Encoder<br/>âš¡ Nhanh"]
    BiEnc --> FAISS["FAISS<br/>Top-50"]
    FAISS --> CE["Cross-Encoder<br/>ğŸ¯ ChÃ­nh xÃ¡c"]
    CE --> Top10["Top-10<br/>Káº¿t quáº£ cuá»‘i"]

    style BiEnc fill:#4CAF50,color:#fff
    style CE fill:#2196F3,color:#fff
```

### Model: `ms-marco-MiniLM-L-6-v2` (~87 MB ONNX)

### âŒ Váº¥n Ä‘á» nghiÃªm trá»ng

Model **chá»‰ train trÃªn tiáº¿ng Anh** (MS MARCO dataset). Khi re-rank cÃ¢u há»i tiáº¿ng Viá»‡t â†’ scoring gáº§n nhÆ° ngáº«u nhiÃªn â†’ cÃ¢u tráº£ lá»i lá»‡ch xa cÃ¢u há»i.

```mermaid
graph LR
    subgraph "ms-marco scoring tiáº¿ng Viá»‡t"
        Q1["'Tráº§n HÆ°ng Äáº¡o<br/>Ä‘Ã¡nh NguyÃªn MÃ´ng'"]
        E1["âœ… Báº¡ch Äáº±ng 1288<br/>Score: +2.1"]
        E2["âŒ LÃ½ ThÃ¡i Tá»• 1010<br/>Score: +1.9"]
    end
    Q1 --> E1
    Q1 --> E2
    E1 -.- Note1["ChÃªnh lá»‡ch chá»‰ 0.2<br/>âŒ KhÃ´ng phÃ¢n biá»‡t Ä‘Æ°á»£c!"]

    style E1 fill:#E8F5E9
    style E2 fill:#FFEBEE
    style Note1 fill:#FFF3E0,stroke:#FF9800
```

> **BÃ i há»c:** Cross-encoder train trÃªn tiáº¿ng Anh **KHÃ”NG THá»‚** re-rank tiáº¿ng Viá»‡t. ÄÃ¢y lÃ  bottleneck lá»›n nháº¥t.

---

## Giai Ä‘oáº¡n 4: NghiÃªn cá»©u giáº£i phÃ¡p nÃ¢ng cao

### 3 hÆ°á»›ng Ä‘i Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡

```mermaid
graph TD
    Root["Cáº£i thiá»‡n cháº¥t lÆ°á»£ng<br/>cÃ¢u tráº£ lá»i"] --> H1["ğŸ”´ HÆ°á»›ng 1<br/>API LLM"]
    Root --> H2["ğŸ”´ HÆ°á»›ng 2<br/>Local LLM 7B"]
    Root --> H3["ğŸŸ¢ HÆ°á»›ng 3<br/>NÃ¢ng cáº¥p Pipeline"]

    H1 --> H1R["GPT-4, Claude, Gemini<br/>~$30/1M tokens<br/>Phá»¥ thuá»™c internet"]
    H1R --> H1X["âŒ Loáº¡i: Tá»‘n phÃ­"]

    H2 --> H2R["Qwen 7B: 14 GB<br/>Vistral 7B: 14 GB<br/>Gemma 9B: 18 GB"]
    H2R --> H2X["âŒ Loáº¡i: QuÃ¡ lá»›n<br/>Railway chá»‰ ~512 MB RAM"]

    H3 --> H3R["Cross-Encoder Multilingual<br/>+ NLI Validator<br/>~100 MB má»—i model"]
    H3R --> H3X["âœ… CHá»ŒN<br/>Miá»…n phÃ­, ONNX, nháº¹"]

    style H1X fill:#FFCDD2,stroke:#F44336
    style H2X fill:#FFCDD2,stroke:#F44336
    style H3X fill:#C8E6C9,stroke:#4CAF50
```

### Chi tiáº¿t lÃ½ do loáº¡i bá» tá»«ng hÆ°á»›ng

```mermaid
graph LR
    subgraph "âŒ API LLM"
        direction TB
        A1["âœ… Hiá»ƒu TV xuáº¥t sáº¯c"]
        A2["âŒ Tá»‘n tiá»n<br/>GPT-4: ~$30/1M tokens"]
        A3["âŒ Phá»¥ thuá»™c internet"]
        A4["âŒ Latency 1-3s/query"]
    end

    subgraph "âŒ Local LLM 7B"
        direction TB
        B1["âœ… Miá»…n phÃ­"]
        B2["âŒ 14-18 GB model"]
        B3["âŒ Cáº§n GPU"]
        B4["âŒ KhÃ´ng push<br/>Ä‘Æ°á»£c GitHub"]
    end

    subgraph "âœ… NÃ¢ng cáº¥p Pipeline"
        direction TB
        C1["âœ… Miá»…n phÃ­"]
        C2["âœ… ~100 MB/model"]
        C3["âœ… CPU only"]
        C4["âœ… Deploy Railway"]
    end
```

---

## Giai Ä‘oáº¡n 5: Cross-Encoder Multilingual âœ…

### Model má»›i: `mmarco-mMiniLMv2-L12-H384-v1`

**LÃ½ do chá»n:**
- Train trÃªn **mMARCO** â€” phiÃªn báº£n multilingual cá»§a MS MARCO
- **14 ngÃ´n ngá»¯** bao gá»“m tiáº¿ng Viá»‡t
- CÃ¹ng kiáº¿n trÃºc MiniLM â†’ tÆ°Æ¡ng thÃ­ch ONNX
- Quantized: **~113 MB** (chá»‰ tÄƒng 26 MB so vá»›i cÅ©)

### Káº¿t quáº£ thá»±c táº¿

```mermaid
graph LR
    subgraph "Káº¿t quáº£ mmarco multilingual"
        Q["'Tráº§n HÆ°ng Äáº¡o<br/>Ä‘Ã¡nh NguyÃªn MÃ´ng'"]
        R1["âœ… Báº¡ch Äáº±ng 1288<br/>Score: +9.05"]
        R2["âŒ HCM 1945<br/>Score: -4.11"]
        R3["âŒ LÃ½ ThÃ¡i Tá»• 1010<br/>Score: -4.15"]
    end
    Q --> R1
    Q --> R2
    Q --> R3
    R1 -.- Note["ChÃªnh lá»‡ch ~13 Ä‘iá»ƒm<br/>âœ… PhÃ¢n biá»‡t cá»±c rÃµ!"]

    style R1 fill:#C8E6C9,stroke:#4CAF50
    style R2 fill:#FFCDD2,stroke:#F44336
    style R3 fill:#FFCDD2,stroke:#F44336
    style Note fill:#E8F5E9,stroke:#4CAF50
```

### So sÃ¡nh trÆ°á»›c / sau

```mermaid
graph LR
    subgraph "TRÆ¯á»šC: ms-marco English"
        A["ChÃªnh lá»‡ch ~0.2<br/>âŒ Gáº§n nhÆ° báº±ng nhau"]
    end
    subgraph "SAU: mmarco Multilingual"
        B["ChÃªnh lá»‡ch ~13<br/>âœ… Cá»±c rÃµ rÃ ng"]
    end
    A -->|"Thay tháº¿"| B

    style A fill:#FFCDD2,stroke:#F44336
    style B fill:#C8E6C9,stroke:#4CAF50
```

---

## Giai Ä‘oáº¡n 6: NLI Answer Validator âœ…

### Váº¥n Ä‘á» cÃ²n láº¡i

Cross-encoder re-rank tá»‘t hÆ¡n rá»“i, nhÆ°ng váº«n cÃ³ trÆ°á»ng há»£p event "gáº§n Ä‘Ãºng" nhÆ°ng khÃ´ng thá»±c sá»± tráº£ lá»i cÃ¢u há»i.

```mermaid
graph TD
    Q["'NÄƒm 1945 cÃ³ sá»± kiá»‡n gÃ¬?'"] --> E1["TuyÃªn ngÃ´n Äá»™c láº­p 1945<br/>âœ… ÄÃºng nÄƒm"]
    Q --> E2["Äiá»‡n BiÃªn Phá»§ 1954<br/>âŒ Sai nÄƒm!"]
    E2 -.- Note["Cross-encoder score váº«n cao<br/>vÃ¬ cÃ¹ng chá»§ Ä‘á» chiáº¿n tranh"]

    style E1 fill:#C8E6C9,stroke:#4CAF50
    style E2 fill:#FFCDD2,stroke:#F44336
    style Note fill:#FFF3E0,stroke:#FF9800
```

### Giáº£i phÃ¡p: Natural Language Inference (NLI)

NLI kiá»ƒm tra: **"Event nÃ y cÃ³ Há»– TRá»¢ (entail) cÃ¢u há»i khÃ´ng?"**

```mermaid
graph LR
    subgraph "3 nhÃ£n NLI"
        E["ğŸŸ¢ Entailment<br/>Event tráº£ lá»i Ä‘Ãºng cÃ¢u há»i"]
        N["ğŸŸ¡ Neutral<br/>LiÃªn quan nhÆ°ng khÃ´ng<br/>tráº£ lá»i trá»±c tiáº¿p"]
        C["ğŸ”´ Contradiction<br/>MÃ¢u thuáº«n vá»›i cÃ¢u há»i"]
    end
```

### Táº¡i sao chá»n `MiniLMv2-L6-mnli-xnli`?

```mermaid
graph TD
    subgraph "âŒ mDeBERTa-v3-base-xnli"
        D1["Cháº¥t lÆ°á»£ng: Cao hÆ¡n"]
        D2["ONNX: ~280 MB ğŸ”´"]
        D3["Tá»‘c Ä‘á»™: Cháº­m"]
        D4["Railway: KhÃ³ fit RAM"]
    end
    subgraph "âœ… MiniLMv2-L6-mnli-xnli"
        M1["Cháº¥t lÆ°á»£ng: Äá»§ tá»‘t"]
        M2["ONNX: ~102 MB ğŸŸ¢"]
        M3["Tá»‘c Ä‘á»™: Nhanh 2x"]
        M4["Railway: Vá»«a Ä‘á»§ âœ…"]
    end
    D1 -.->|"Trade-off<br/>nháº¹ hÆ¡n 2.7x"| M1

    style D2 fill:#FFCDD2
    style M2 fill:#C8E6C9
    style M4 fill:#C8E6C9
```

### Káº¿t quáº£ NLI filtering

```mermaid
graph LR
    subgraph "Query: 'Ai Ä‘Ã¡nh quÃ¢n NguyÃªn MÃ´ng?'"
        E1["Tráº§n HÆ°ng Äáº¡o<br/>Báº¡ch Äáº±ng 1288"]
        E2["LÃ½ ThÃ¡i Tá»•<br/>dá»i Ä‘Ã´ 1010"]
    end

    E1 --> R1["E=0.24 > C=0.17<br/>ğŸŸ¢ KEEP"]
    E2 --> R2["E=0.08 < 0.20<br/>ğŸ”´ FILTER"]

    style R1 fill:#C8E6C9,stroke:#4CAF50
    style R2 fill:#FFCDD2,stroke:#F44336
```

---

## Giai Ä‘oáº¡n 7: Intent Classifier + Answer Synthesis âœ…

### Váº¥n Ä‘á»

Pipeline NLI + Cross-Encoder tÃ¬m Ä‘Ãºng káº¿t quáº£, nhÆ°ng **cÃ¡ch tráº£ lá»i chÆ°a thÃ´ng minh**:

- CÃ¢u há»i "khi nÃ o" â†’ tráº£ láº¡i danh sÃ¡ch dÃ i thay vÃ¬ chá»‰ nÃªu nÄƒm
- CÃ¢u há»i "ai" â†’ dump toÃ n bá»™ sá»± kiá»‡n thay vÃ¬ táº­p trung nhÃ¢n váº­t
- CÃ¢u há»i "liá»‡t kÃª" â†’ khÃ´ng nhÃ³m theo thá»i ká»³
- "1000 nÄƒm ThÄƒng Long" â†’ hiá»ƒu nháº§m thÃ nh nÄƒm 1000

### Giáº£i phÃ¡p: Intent Classifier

PhÃ¢n loáº¡i cÃ¢u há»i thÃ nh **10 intent types** trÆ°á»›c khi xá»­ lÃ½:

```mermaid
graph TD
    Q["ğŸ“ CÃ¢u há»i"] --> IC["ğŸ¯ Intent Classifier"]

    IC --> I1["year_range<br/>'Tá»« 1945 Ä‘áº¿n 1975'"]
    IC --> I2["year_specific<br/>'NÄƒm 1945 cÃ³ gÃ¬?'"]
    IC --> I3["person_query<br/>'Tráº§n HÆ°ng Äáº¡o Ä‘Ã¡nh gÃ¬?'"]
    IC --> I4["dynasty_query<br/>'NhÃ  Tráº§n tá»“n táº¡i bao lÃ¢u?'"]
    IC --> I5["event_query<br/>'Tráº­n Báº¡ch Äáº±ng'"]
    IC --> I6["definition<br/>'X lÃ  ai?'"]
    IC --> I7["relationship<br/>'A vÃ  B lÃ  gÃ¬ cá»§a nhau?'"]
    IC --> I8["broad_history<br/>'Lá»‹ch sá»­ VN'"]
    IC --> I9["data_scope<br/>'Dataset cÃ³ gÃ¬?'"]
    IC --> I10["semantic<br/>Fallback"]

    style IC fill:#1b4332,color:#fff
    style I1 fill:#E3F2FD
    style I2 fill:#E3F2FD
    style I3 fill:#FFF3E0
    style I4 fill:#FFF3E0
    style I5 fill:#E8F5E9
    style I6 fill:#E8F5E9
    style I7 fill:#F3E5F5
    style I8 fill:#F3E5F5
    style I9 fill:#FCE4EC
    style I10 fill:#ECEFF1
```

### Duration Guard

PhÃ¢n biá»‡t **"X nÄƒm"** lÃ  thá»i gian hay nÄƒm lá»‹ch sá»­:

| Input | PhÃ¢n loáº¡i | Giáº£i thÃ­ch |
|-------|-----------|------------|
| "ká»· niá»‡m 1000 nÄƒm ThÄƒng Long" | â±ï¸ Duration | 1000 lÃ  sá»‘ nÄƒm, khÃ´ng pháº£i nÄƒm 1000 |
| "hÆ¡n 150 nÄƒm chia cáº¯t" | â±ï¸ Duration | 150 lÃ  thá»i gian |
| "nÄƒm 1945" | ğŸ“… Year | NÄƒm lá»‹ch sá»­ cá»¥ thá»ƒ |
| "sá»± kiá»‡n nÄƒm 1010" | ğŸ“… Year | NÄƒm lá»‹ch sá»­ cá»¥ thá»ƒ |

### Answer Synthesis

Äiá»u chá»‰nh format cÃ¢u tráº£ lá»i theo **question_type**:

```mermaid
graph LR
    subgraph "Question Type â†’ Format"
        WHEN["when<br/>'Khi nÃ o?'"] --> WHEN_F["NÄƒm + bá»‘i cáº£nh ngáº¯n"]
        WHO["who<br/>'Ai?'"] --> WHO_F["Tiá»ƒu sá»­ + sá»± kiá»‡n chÃ­nh"]
        WHAT["what<br/>'GÃ¬?'"] --> WHAT_F["MÃ´ táº£ sá»± kiá»‡n chi tiáº¿t"]
        LIST["list<br/>'Liá»‡t kÃª'"] --> LIST_F["NhÃ³m theo thá»i ká»³"]
        SCOPE["scope<br/>'Pháº¡m vi?'"] --> SCOPE_F["Thá»‘ng kÃª dataset"]
    end

    style WHEN fill:#E3F2FD
    style WHO fill:#FFF3E0
    style WHAT fill:#E8F5E9
    style LIST fill:#F3E5F5
    style SCOPE fill:#FCE4EC
```

---

## Giai Ä‘oáº¡n 8: Data-Driven Architecture âœ…

### Váº¥n Ä‘á»

Há»‡ thá»‘ng trÆ°á»›c Ä‘Ã³ hard-code aliases, synonyms trong code Python â†’ **má»—i láº§n thÃªm nhÃ¢n váº­t / chá»§ Ä‘á» má»›i pháº£i sá»­a code, commit, deploy láº¡i**.

### Giáº£i phÃ¡p: `knowledge_base.json`

**Single Source of Truth** â€” táº¥t cáº£ dá»¯ liá»‡u Ä‘á»™ng load tá»« 1 file JSON:

```mermaid
graph TD
    KB["ğŸ“„ knowledge_base.json"] --> S1["person_aliases<br/>Tráº§n Quá»‘c Tuáº¥n â†’ Tráº§n HÆ°ng Äáº¡o"]
    KB --> S2["topic_synonyms<br/>MÃ´ng Cá»• â†’ NguyÃªn MÃ´ng"]
    KB --> S3["dynasty_aliases<br/>NhÃ  Tráº§n â†’ Tráº§n"]
    KB --> S4["abbreviations<br/>HCM â†’ Há»“ ChÃ­ Minh"]
    KB --> S5["typo_fixes<br/>quangtrung â†’ quang trung"]
    KB --> S6["question_patterns<br/>ai Ä‘Ã£, khi nÃ o, á»Ÿ Ä‘Ã¢u"]
    KB --> S7["resistance_synonyms<br/>khÃ¡ng chiáº¿n â†’ [cÃ¡c cuá»™c chiáº¿n]"]

    S1 & S2 & S3 & S4 & S5 & S6 & S7 --> STARTUP["ğŸš€ Startup<br/>Auto-build indexes"]
    STARTUP --> IDX1["ğŸ“‡ PERSON_INDEX"]
    STARTUP --> IDX2["ğŸ“‡ DYNASTY_INDEX"]
    STARTUP --> IDX3["ğŸ“‡ KEYWORD_INDEX"]
    STARTUP --> IDX4["ğŸ“‡ ENTITY_YEAR_INDEX"]

    style KB fill:#FFF3E0,stroke:#FF9800
    style STARTUP fill:#E8F5E9,stroke:#4CAF50
```

### Implicit Context Layer

Xá»­ lÃ½ Ä‘áº·c thÃ¹ 100% dataset lÃ  lá»‹ch sá»­ Viá»‡t Nam:

- **"Viá»‡t Nam"** khÃ´ng pháº£i keyword phÃ¢n biá»‡t â†’ tá»± Ä‘á»™ng bá» qua khi filter
- **KhÃ¡ng chiáº¿n** â†’ tá»± Ä‘á»™ng má»Ÿ rá»™ng thÃ nh cÃ¡c cuá»™c chiáº¿n cá»¥ thá»ƒ
- **Query rá»™ng** â†’ thÃªm search queries Ä‘á»ƒ bao phá»§ nhiá»u triá»u Ä‘áº¡i

---

## Giai Ä‘oáº¡n 9: Robustness + Bug Fixing âœ…

### Váº¥n Ä‘á»

Khi scale lÃªn 500K+ documents, xuáº¥t hiá»‡n cÃ¡c edge cases:

- **Null/empty fields**: Story hoáº·c event lÃ  `None`, empty string
- **Malformed data types**: Year lÃ  string, story lÃ  integer/list/dict
- **FAISS negative indices**: Index tráº£ vá» `-1` khi khÃ´ng tÃ¬m tháº¥y
- **Empty max() calls**: KhÃ´ng cÃ³ valid scores Ä‘á»ƒ so sÃ¡nh

### 7 bugs Ä‘Æ°á»£c fix

| Bug | MÃ´ táº£ | áº¢nh hÆ°á»Ÿng |
|-----|-------|-----------|
| #1 | `clean_story[0].upper()` crash khi string rá»—ng | Server crash |
| #2 | `max()` trÃªn empty list | Server crash |
| #4 | `None` passed to string operations | Server crash |
| #5 | FAISS negative indices `-1` â†’ array access | Káº¿t quáº£ sai |
| â€” | `len(non-string)` crash trong sort | Server crash |
| â€” | Unhashable year types (list, dict) | Server crash |
| â€” | None years break sort comparison | Server crash |

### Type Safety Ä‘Æ°á»£c thÃªm vÃ o

```mermaid
graph LR
    subgraph "TrÆ°á»›c: Crash vá»›i data xáº¥u"
        B1["story = 12345<br/>âŒ len(12345)"]
        B2["year = [1945]<br/>âŒ unhashable"]
        B3["story = None<br/>âŒ None.strip()"]
    end

    subgraph "Sau: Handles gracefully"
        A1["story = 12345<br/>âœ… str(12345)"]
        A2["year = [1945]<br/>âœ… int(1945)"]
        A3["story = None<br/>âœ… return empty"]
    end

    B1 -->|"Type coercion"| A1
    B2 -->|"Year coercion"| A2
    B3 -->|"Null safety"| A3

    style B1 fill:#FFCDD2
    style B2 fill:#FFCDD2
    style B3 fill:#FFCDD2
    style A1 fill:#C8E6C9
    style A2 fill:#C8E6C9
    style A3 fill:#C8E6C9
```

### Test Suite: 629+ tests

| Category | Files | Tests |
|----------|-------|-------|
| Engine | 3 | 78 + 35 + 16 = 129 |
| NLU | 3 | 55 + 30 + 53 = 138 |
| Integration | 2 | 74 + 30 = 104 |
| Pipeline | 3 | 30 + 20 + 30 = 80 |
| API & Schema | 4 | 68 |
| Performance | 2 | 36 |
| Others | 7 | 74 |
| **Tá»•ng** | **24** | **629+** |

---

## Kiáº¿n trÃºc hiá»‡n táº¡i (v4.0)

```mermaid
flowchart TD
    Q["ğŸ“ CÃ¢u há»i ngÆ°á»i dÃ¹ng"] --> NLU

    subgraph NLU["ğŸ”¤ Query Understanding"]
        direction TB
        N1["Sá»­a lá»—i chÃ­nh táº£"]
        N2["KhÃ´i phá»¥c dáº¥u tiáº¿ng Viá»‡t"]
        N3["Má»Ÿ rá»™ng viáº¿t táº¯t"]
        N4["Entity detection"]
    end

    NLU --> IC

    subgraph IC["ğŸ¯ Intent Classifier â€” 10 intent types"]
        direction TB
        IC1["PhÃ¢n loáº¡i cÃ¢u há»i"]
        IC2["Duration guard"]
        IC3["Question type detection"]
    end

    IC --> Search

    subgraph Search["ğŸ” Semantic Search â€” vietnamese-sbert ONNX 130 MB"]
        direction TB
        S1["Encode cÃ¢u há»i â†’ vector"]
        S2["FAISS similarity search"]
        S3["Entity scan tá»« inverted index"]
    end

    Search -->|"Top-50 events"| Rerank

    subgraph Rerank["ğŸ“Š Cross-Encoder Rerank â€” mmarco ONNX 113 MB"]
        direction TB
        R1["Score tá»«ng cáº·p query-event"]
        R2["Sort theo relevance score"]
    end

    Rerank -->|"Top-10 events"| NLI

    subgraph NLI["âœ… NLI Validator â€” MiniLMv2 ONNX 102 MB"]
        direction TB
        V1["Kiá»ƒm tra entailment per event"]
        V2["Loáº¡i bá» contradiction events"]
    end

    NLI -->|"Filtered events"| Synth

    subgraph Synth["ğŸ“„ Answer Synthesis"]
        direction TB
        AS1["Template-based formatting"]
        AS2["Question-type aware verbosity"]
        AS3["Period grouping cho list queries"]
    end

    Synth -->|"Implicit context"| Format

    subgraph Format["ğŸŒ Implicit Context"]
        direction TB
        F1["Vietnam scope detection"]
        F2["Resistance term expansion"]
        F3["Non-discriminating keyword filter"]
    end

    Format --> A["ğŸ’¬ CÃ¢u tráº£ lá»i"]

    style Q fill:#E3F2FD,stroke:#1565C0
    style A fill:#E8F5E9,stroke:#2E7D32
    style IC fill:#1b4332,color:#fff
    style Search fill:#FFF3E0,stroke:#FF9800
    style Rerank fill:#E8EAF6,stroke:#3F51B5
    style NLI fill:#F3E5F5,stroke:#7B1FA2
    style Synth fill:#FFF8E1,stroke:#FF6F00
```

## Tá»•ng kÃ­ch thÆ°á»›c Models

```mermaid
pie title Dung lÆ°á»£ng Models (345 MB tá»•ng)
    "Embedding vietnamese-sbert" : 130
    "Cross-Encoder mmarco" : 113
    "NLI Validator MiniLMv2" : 102
```

> Táº¥t cáº£ cháº¡y trÃªn **CPU** â€” khÃ´ng cáº§n GPU. Tá»•ng RAM khi cháº¡y â‰ˆ 400-500 MB.

---

## Tá»•ng há»£p cÃ¡c phÆ°Æ¡ng Ã¡n Ä‘Ã£ cÃ¢n nháº¯c

```mermaid
graph TD
    subgraph "âŒ ÄÃƒ LOáº I Bá»"
        X1["GPT-4 / Claude API<br/>LÃ½ do: Tá»‘n phÃ­"]
        X2["Local LLM 7B<br/>Qwen, Vistral<br/>LÃ½ do: 14 GB, cáº§n GPU"]
        X3["BAAI/bge-m3 embedding<br/>LÃ½ do: 1.2 GB, khÃ´ng cáº§n thiáº¿t"]
        X4["BAAI/bge-reranker-v2-m3<br/>LÃ½ do: Lá»›n hÆ¡n mmarco"]
        X5["mDeBERTa-v3 NLI<br/>LÃ½ do: 280 MB, quÃ¡ náº·ng"]
        X6["LangChain RAG<br/>LÃ½ do: Overkill, dependency lá»›n"]
    end

    subgraph "âœ… ÄÃƒ CHá»ŒN"
        C1["vietnamese-sbert<br/>130 MB ONNX"]
        C2["mmarco cross-encoder<br/>113 MB ONNX"]
        C3["MiniLMv2-L6 NLI<br/>102 MB ONNX"]
    end

    style X1 fill:#FFCDD2,stroke:#F44336
    style X2 fill:#FFCDD2,stroke:#F44336
    style X3 fill:#FFCDD2,stroke:#F44336
    style X4 fill:#FFCDD2,stroke:#F44336
    style X5 fill:#FFCDD2,stroke:#F44336
    style X6 fill:#FFCDD2,stroke:#F44336
    style C1 fill:#C8E6C9,stroke:#4CAF50
    style C2 fill:#C8E6C9,stroke:#4CAF50
    style C3 fill:#C8E6C9,stroke:#4CAF50
```

---

## HÆ°á»›ng phÃ¡t triá»ƒn tiáº¿p theo

```mermaid
graph LR
    Now["Hiá»‡n táº¡i v4.0<br/>Semantic Search<br/>+ Rerank + NLI<br/>+ Intent + Synthesis"] --> F1["ğŸ”œ Claude LLM<br/>Sinh cÃ¢u tráº£ lá»i<br/>tá»± nhiÃªn hÆ¡n<br/>(fallback to rule-based)"]
    Now --> F2["ğŸ”œ Fine-tune<br/>Cross-Encoder<br/>trÃªn dá»¯ liá»‡u VN"]
    Now --> F3["ğŸ”œ Hybrid Search<br/>BM25 + Semantic"]
    Now --> F4["ğŸ”œ User Feedback<br/>thumb up/down<br/>cáº£i thiá»‡n ranking"]

    style Now fill:#E3F2FD,stroke:#1565C0
    style F1 fill:#FFF9C4,stroke:#F9A825
    style F2 fill:#FFF9C4,stroke:#F9A825
    style F3 fill:#FFF9C4,stroke:#F9A825
    style F4 fill:#FFF9C4,stroke:#F9A825
```

---

*Cáº­p nháº­t láº§n cuá»‘i: 2026-02-15*
